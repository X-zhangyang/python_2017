model：ssd_mobilenet_v1_

第一次实验：（2017.08.25 - 2017.09.03）

使用数据 1st_gun_data   
本次实验总结出了一套较为完整的训练步骤，之后可以根据步骤训练其他数据。数据格式为 PASCAL VOC格式。


实验结果 ：
总共得到有效结果 4个 （16293,40153,61272,68843 steps）
选择 68843 数据尽心测试。
image 测试：效果还不错，符合期望。
video 测试：未测试
online 测试：效果较差，      （摄像头较差？ online脚本处理方式还未完全理解透彻）

不足：目前看来只能识别出正面且完整的图片，侧视图效果较差    （推测与训练模型的数据有关？）

总结：
1，用于训练模型的样本数据较为关键，在第二实验中会增加侧面图片，以及其他形态下的图片。
2，本次选择的模型为现有的 ssd_mobilenet_v1 模型，考虑尝试其他模型。
3，使用python对视频操作，抓取每一帧图片，可以剪切视频，制作gif图片，还有很多操作，需要学习。
4，fl_image 函数是做什么的？
5，理解了整个框架结构，特别是image和video测试，online测试还有待理解。
6，仍未掌握 tensorboard 的使用方法。
7，

第一次实验结束。


第二次实验：（2017..09.03 - 2017.09.05 ）

使用 1st_plus_2nd_data  在第一次实验的基础上增加了新样本数据  2nd_gun_data为新增数据
实验结果：
第一次结果 27694 steps： online测试不理想，误判严重。可能是由于样本较多且形态较多，训练次数不足导致的。 
可以测试部分侧视图片，仍未达到预期。
第二次结果 36964 steps： 测试中出现了奇怪现象，同一长图片，截取不同长短，效果不一。？因为训练数据中”矮长“图片多？
第三次结果 90797 steps：效果必之前效果略好，可以检测出之前无法检测出的图片。
目前推测检测精确度应该与model有较大关系。之后打算训练一个其他模型。

第二次实验结束。



第三次实验：（2017.09.06 - 2017.09.0 ）
把 raccoon 数据添加到 第二次试验中，本次实验尝试训练2种不同物体（raccoon and gun）。 记得修改config文件中class数量。
注意修改 xml文件中的 class  （name）
第一次结果  57004 steps: 成功检测出2种物体（raccoon&gun）。 还需更多测试
 



